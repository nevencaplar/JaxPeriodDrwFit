{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import time\n",
    "import JaxPeriodDrwFit\n",
    "# import dill as pickle\n",
    "import cloudpickle as pickle\n",
    "\n",
    "from tape.ensemble import Ensemble\n",
    "from tape.utils import ColumnMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated in create_data script, to avoid epyc failure\n",
    "t_multi = np.load('/astro/users/ncaplar/data/t_multi.npy')\n",
    "y_multi = np.load('/astro/users/ncaplar/data/y_multi.npy')\n",
    "yerr_multi = np.load('/astro/users/ncaplar/data/yerr_multi.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:distributed.http.proxy:To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "INFO:distributed.scheduler:State start\n",
      "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:44160\n",
      "INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:8787/status\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:41520'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:37047'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:35172'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:36807'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:34044'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:42496'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:38329'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:33869'\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:42917', name: 0, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:42917\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:54328\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:34267', name: 1, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:34267\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:54330\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:45823', name: 5, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:45823\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:54332\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:44552', name: 7, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:44552\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:54334\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:40947', name: 3, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:40947\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:54336\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:34247', name: 4, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:34247\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:54338\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:34876', name: 6, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:34876\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:54340\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:39852', name: 2, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:39852\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:54342\n",
      "INFO:distributed.scheduler:Receive client connection: Client-452ecec5-4504-11ee-bbea-b42e99a8502c\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:54344\n"
     ]
    }
   ],
   "source": [
    "\n",
    "id, t, y, yerr, filter = np.array([]), np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "for i in range(100):\n",
    "    # data = data_all[()].get(i)\n",
    "\n",
    "    # get time for a single lightcurve\n",
    "    t_true = t_multi[i]\n",
    "    # sample 100 points from 200\n",
    "    downsample_int = np.sort(np.random.choice(np.arange(len(t_true)), 100))\n",
    "    # extract 100 times from 200\n",
    "    t_single = t_true[downsample_int]\n",
    "\n",
    "    id = np.append(id, np.full(len(downsample_int), i))\n",
    "    filter_single = np.full(len(t_single), 'r')\n",
    "    t = np.append(t, t_single)\n",
    "    filter = np.append(filter, filter_single)\n",
    "\n",
    "    # create custom errors\n",
    "    y_err_single = np.full(len(t_single), 0.001)\n",
    "    yerr = np.append(yerr, np.full(len(t_single), 0.001))\n",
    "\n",
    "    # extract measurements; 100 from each lightcurve\n",
    "    # y_pre = data['y_tot'][downsample_int]\n",
    "    y_pre = y_multi[i][downsample_int]\n",
    "\n",
    "    # create noise and add to lightcurves\n",
    "    noise = np.random.normal(0, y_err_single)\n",
    "    y = np.append(y, y_pre + noise)\n",
    "\n",
    "# columns assigned manually\n",
    "manual_colmap = ColumnMapper().assign(\n",
    "    id_col=\"id\", time_col=\"t\", flux_col=\"y\", err_col=\"yerr\", band_col=\"filter\"\n",
    ")\n",
    "\n",
    "ens = Ensemble()\n",
    "ens.from_source_dict({'id': id, \"t\": t, 'y': y, 'yerr': yerr, 'filter': filter},\n",
    "                        column_mapper=manual_colmap)\n",
    "single_lc = ens.compute(\"source\")[id == 0]\n",
    "# comment out line below if trying to run ensamble.batch\n",
    "# ens.client.close()\n",
    "##########\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "JaxPeriodDrwFit_instance = JaxPeriodDrwFit.JaxPeriodDrwFit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>filter</th>\n",
       "      <th>nobs_r</th>\n",
       "      <th>nobs_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "filter  nobs_r  nobs_total\n",
       "id                        \n",
       "0.0        100         100\n",
       "1.0        100         100\n",
       "2.0        100         100\n",
       "3.0        100         100\n",
       "4.0        100         100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens.head(\"object\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>y</th>\n",
       "      <th>yerr</th>\n",
       "      <th>filter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>100.750075</td>\n",
       "      <td>-0.279083</td>\n",
       "      <td>0.001</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>101.845185</td>\n",
       "      <td>-0.250719</td>\n",
       "      <td>0.001</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>104.035404</td>\n",
       "      <td>-0.179370</td>\n",
       "      <td>0.001</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>160.981098</td>\n",
       "      <td>0.099968</td>\n",
       "      <td>0.001</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>181.423142</td>\n",
       "      <td>0.037428</td>\n",
       "      <td>0.001</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              t         y   yerr filter\n",
       "id                                     \n",
       "0.0  100.750075 -0.279083  0.001      r\n",
       "0.0  101.845185 -0.250719  0.001      r\n",
       "0.0  104.035404 -0.179370  0.001      r\n",
       "0.0  160.981098  0.099968  0.001      r\n",
       "0.0  181.423142  0.037428  0.001      r"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens.head(\"source\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "0.0     [-130.9124282376623, 1.9940229510834508, -0.79...\n",
      "1.0     [-121.419540418573, 2.1799845126346407, -0.710...\n",
      "2.0     [-130.07752684151336, 1.9703068037069376, -0.8...\n",
      "3.0     [-121.0830567877342, 2.0018271214347214, -0.78...\n",
      "4.0     [-128.58517651196684, 1.9173932408575038, -0.8...\n",
      "                              ...                        \n",
      "95.0    [-133.53417385356724, 2.2511764821387024, -0.7...\n",
      "96.0    [-131.89283492618694, 1.8781759511073668, -0.8...\n",
      "97.0    [-126.5910879300794, 2.325249051470435, -0.668...\n",
      "98.0    [-135.91441737620806, 1.936658843185543, -0.84...\n",
      "99.0    [-122.93198917600216, 2.176840636105713, -0.72...\n",
      "Name: id, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# it works here !?!?\n",
    "res = ens.batch(JaxPeriodDrwFit_instance.optimize_map, 't', 'y', 'yerr',\n",
    "                 compute=True, meta=None, n_init=100)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:41520'. Reason: nanny-close\n",
      "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
      "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:37047'. Reason: nanny-close\n",
      "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
      "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:35172'. Reason: nanny-close\n",
      "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
      "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:36807'. Reason: nanny-close\n",
      "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
      "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:34044'. Reason: nanny-close\n",
      "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
      "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:42496'. Reason: nanny-close\n",
      "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
      "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:38329'. Reason: nanny-close\n",
      "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
      "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:33869'. Reason: nanny-close\n",
      "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
      "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:54328; closing.\n",
      "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:54330; closing.\n",
      "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:54342; closing.\n",
      "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:54336; closing.\n",
      "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:54338; closing.\n",
      "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:54332; closing.\n",
      "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:54340; closing.\n",
      "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:42917', name: 0, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1693159542.3967216')\n",
      "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:34267', name: 1, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1693159542.3977008')\n",
      "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:39852', name: 2, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1693159542.3984973')\n",
      "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:40947', name: 3, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1693159542.3992505')\n",
      "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:34247', name: 4, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1693159542.3999908')\n",
      "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:45823', name: 5, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1693159542.400781')\n",
      "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:34876', name: 6, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1693159542.401519')\n",
      "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:54334; closing.\n",
      "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:44552', name: 7, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1693159542.4034584')\n",
      "INFO:distributed.scheduler:Lost all workers\n",
      "INFO:distributed.batched:Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:44160 remote=tcp://127.0.0.1:54334>\n",
      "Traceback (most recent call last):\n",
      "  File \"/astro/users/ncaplar/miniconda3/envs/jax_gpu/lib/python3.11/site-packages/distributed/batched.py\", line 115, in _background_send\n",
      "    nbytes = yield coro\n",
      "             ^^^^^^^^^^\n",
      "  File \"/astro/users/ncaplar/miniconda3/envs/jax_gpu/lib/python3.11/site-packages/tornado/gen.py\", line 769, in run\n",
      "    value = future.result()\n",
      "            ^^^^^^^^^^^^^^^\n",
      "  File \"/astro/users/ncaplar/miniconda3/envs/jax_gpu/lib/python3.11/site-packages/distributed/comm/tcp.py\", line 269, in write\n",
      "    raise CommClosedError()\n",
      "distributed.comm.core.CommClosedError\n",
      "INFO:distributed.scheduler:Scheduler closing...\n",
      "INFO:distributed.scheduler:Scheduler closing all comms\n"
     ]
    }
   ],
   "source": [
    "ens.client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for single lc is 4.077223062515259 sec\n",
      "Best result is:[-130.76855682    2.02563672   -0.78154641    0.79178059   -1.65381861]\n",
      "Execution time for second run with single lc is 0.1410675048828125 sec\n",
      "Best result is:[-131.83079473    1.90012218   -0.83150308    2.79918596   -1.01825057]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "t = single_lc['t'].values\n",
    "y = single_lc['y'].values\n",
    "yerr = single_lc['yerr'].values\n",
    "\n",
    "# This block shows that the code works on a single lightcurve\n",
    "# And it is faster second time\n",
    "t1 = time.time()\n",
    "test_single_lc_res = JaxPeriodDrwFit_instance.optimize_map(t, y, yerr, n_init=100)\n",
    "t2 = time.time()\n",
    "print(f'Execution time for single lc is {t2 - t1} sec')\n",
    "print('Best result is:' + str(test_single_lc_res))\n",
    "t1 = time.time()\n",
    "test_single_lc_res = JaxPeriodDrwFit_instance.optimize_map(t, y, yerr, n_init=100)\n",
    "t2 = time.time()\n",
    "print(f'Execution time for second run with single lc is {t2 - t1} sec')\n",
    "print('Best result is:' + str(test_single_lc_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_lsst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
